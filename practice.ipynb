{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import argparse\n",
    "from model import MODEL\n",
    "from run import train, test\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "from dataloader import getDataLoader\n",
    "from earlystop import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu = 0\n",
    "patience = 5\n",
    "max_iter = 100  # number of iterations\n",
    "init_lr = 0.005  # initial learning rate\n",
    "lr_decay = 0.75  # learning rate decay\n",
    "final_lr = 1E-5  # learning rate will not decrease after hitting this threshold\n",
    "dropout = 0.3\n",
    "exercise_embed_dim = 64  # hidden state dim for LSTM\n",
    "hidden_dim = 64\n",
    "layer_num = 2  # layer number for LSTM\n",
    "max_step = 100  # the allowed maximum length of a sequence\n",
    "maxgradnorm = 50.0  # maximum gradient norm\n",
    "Lamda = 1  # hyper-parameter Lamda\n",
    "alpha = 0.2  # alpha\n",
    "num_heads = 4  # number of head attentions\n",
    "mode = 3  # mode of integration function\n",
    "# 1: ca / 2: mul / 3: ca mul / 4: rasch\n",
    "fold = '1'  # number of fold\n",
    "dataset = 'assist2009_B'\n",
    "\n",
    "#when dataset is assist2009_B\n",
    "batch_size = 32\n",
    "n_knowledge_concept = 110  # the kinds of unique questions in the dataset\n",
    "n_exercise = 16891  # the number of unique questions in the dataset\n",
    "data_dir = './data/assist2009_B'  # data directory\n",
    "data_name = 'assist2009_B'  # data set name\n",
    "\n",
    "memory_size = n_knowledge_concept\n",
    "lr = init_lr\n",
    "memory_key_state_dim = exercise_embed_dim\n",
    "memory_value_state_dim = exercise_embed_dim * 2\n",
    "\n",
    "train_data_path = data_dir + \"/\" + data_name + \"_train\" + fold + \".csv\"\n",
    "valid_data_path = data_dir + \"/\" + data_name + \"_valid\" + fold + \".csv\"\n",
    "test_data_path = data_dir + \"/\" + data_name + \"_test\" + fold + \".csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import itertools\n",
    "class DataReader():\n",
    "    def __init__(self, train_path, valid_path, test_path, maxstep, numofques):\n",
    "        self.train_path = train_path\n",
    "        self.valid_path = valid_path\n",
    "        self.test_path = test_path\n",
    "        self.maxstep = maxstep\n",
    "        self.numofques = numofques\n",
    "\n",
    "    def getTrainData(self):\n",
    "        print('loading train data...')\n",
    "        q_data= []\n",
    "        qa_data =[]\n",
    "        p_data= []\n",
    "        trainData = []\n",
    "        batch = 0\n",
    "        with open(self.train_path, 'r') as train:\n",
    "            for student, problem, ques, ans in itertools.zip_longest(*[train] * 4):\n",
    "                batch = batch +1\n",
    "                try:\n",
    "                    problem = [int(p) for p in problem.strip().strip(',').split(',')]\n",
    "                    ques = [int(q) for q in ques.strip().strip(',').split(',')]\n",
    "                    ans = [int(a) for a in ans.strip().strip(',').split(',')]\n",
    "                except:\n",
    "                    print(batch)\n",
    "                length = np.size(ques)\n",
    "                slices = length//self.maxstep + (1 if length%self.maxstep > 0 else 0)\n",
    "                for i in range(slices):\n",
    "                    q_temp = np.zeros(shape=[self.maxstep])\n",
    "                    qa_temp = np.zeros(shape=[self.maxstep])\n",
    "                    p_temp = np.zeros(shape=[self.maxstep])\n",
    "                    if length > 0:\n",
    "                        if length >= self.maxstep:\n",
    "                            l = self.maxstep\n",
    "                        else:\n",
    "                            l = length\n",
    "                        for j in range(l):\n",
    "                            q_temp[j] = ques[i*self.maxstep + j]\n",
    "                            qa_temp[j] = ans[i*self.maxstep + j]\n",
    "                            p_temp[j] = problem[i*self.maxstep + j]\n",
    "                        length = length - self.maxstep\n",
    "                    q_data.append(q_temp.tolist())\n",
    "                    qa_data.append(qa_temp.tolist())\n",
    "                    p_data.append(p_temp.tolist())\n",
    "            print('train--question done: ' + str(np.array(q_data).shape))\n",
    "            print('train--question_ans done: ' + str(np.array(qa_data).shape))\n",
    "            print('train--problem done: ' + str(np.array(p_data).shape))\n",
    "            return np.array(q_data).astype(float), np.array(qa_data).astype(float), np.array(p_data).astype(float)\n",
    "\n",
    "    def getValidData(self):\n",
    "        print('loading valid data...')\n",
    "        q_data= []\n",
    "        qa_data =[]\n",
    "        p_data= []\n",
    "        validData = []\n",
    "        batch = 0\n",
    "        with open(self.valid_path, 'r') as valid:\n",
    "            for student, problem, ques, ans in itertools.zip_longest(*[valid] * 4):\n",
    "                batch = batch +1\n",
    "                try:\n",
    "                    problem = [int(p) for p in problem.strip().strip(',').split(',')]\n",
    "                    ques = [int(q) for q in ques.strip().strip(',').split(',')]\n",
    "                    ans = [int(a) for a in ans.strip().strip(',').split(',')]\n",
    "                except:\n",
    "                    print(batch)\n",
    "                length = np.size(ques)\n",
    "                slices = length//self.maxstep + (1 if length%self.maxstep > 0 else 0)\n",
    "                for i in range(slices):\n",
    "                    q_temp = np.zeros(shape=[self.maxstep])\n",
    "                    qa_temp = np.zeros(shape=[self.maxstep])\n",
    "                    p_temp = np.zeros(shape=[self.maxstep])\n",
    "                    if length > 0:\n",
    "                        if length >= self.maxstep:\n",
    "                            l = self.maxstep\n",
    "                        else:\n",
    "                            l = length\n",
    "                        for j in range(l):\n",
    "                            q_temp[j] = ques[i*self.maxstep + j]\n",
    "                            qa_temp[j] = ans[i*self.maxstep + j]\n",
    "                            p_temp[j] = problem[i*self.maxstep + j]\n",
    "                        length = length - self.maxstep\n",
    "                    q_data.append(q_temp.tolist())\n",
    "                    qa_data.append(qa_temp.tolist())\n",
    "                    p_data.append(p_temp.tolist())\n",
    "            print('valid--question done: ' + str(np.array(q_data).shape))\n",
    "            print('valid--question_ans done: ' + str(np.array(qa_data).shape))\n",
    "            print('valid--problem done: ' + str(np.array(p_data).shape))\n",
    "            return np.array(q_data).astype(float), np.array(qa_data).astype(float), np.array(p_data).astype(float)\n",
    "\n",
    "\n",
    "    def getTestData(self):\n",
    "        print('loading test data...')\n",
    "        testData = []\n",
    "        q_data = []\n",
    "        qa_data = []\n",
    "        p_data = []\n",
    "        zero = [0 for i in range(self.numofques * 2)]\n",
    "        batch = 0\n",
    "        with open(self.test_path, 'r') as test:\n",
    "            for student, problem, ques, ans in itertools.zip_longest(*[test] * 4):\n",
    "                #length = int(length.strip().strip(','))\n",
    "                batch = batch + 1\n",
    "                try:\n",
    "                    problem = [int(p) for p in problem.strip().strip(',').split(',')]\n",
    "                    ques = [int(q) for q in ques.strip().strip(',').split(',')]\n",
    "                    ans = [int(a) for a in ans.strip().strip(',').split(',')]\n",
    "                except:\n",
    "                    print(batch)\n",
    "                length = np.size(ques)\n",
    "                slices = length // self.maxstep + (1 if length % self.maxstep > 0 else 0)\n",
    "                for i in range(slices):\n",
    "                    q_temp = np.zeros(shape=[self.maxstep])\n",
    "                    qa_temp = np.zeros(shape=[self.maxstep])\n",
    "                    p_temp = np.zeros(shape=[self.maxstep])\n",
    "                    if length > 0:\n",
    "                        if length >= self.maxstep:\n",
    "                            l = self.maxstep\n",
    "                        else:\n",
    "                            l = length\n",
    "                        for j in range(l):\n",
    "                            q_temp[j] = ques[i * self.maxstep + j]\n",
    "                            qa_temp[j] = ans[i * self.maxstep + j]\n",
    "                            p_temp[j] = problem[i * self.maxstep + j]\n",
    "                        length = length - self.maxstep\n",
    "                    q_data.append(q_temp.tolist())\n",
    "                    qa_data.append(qa_temp.tolist())\n",
    "                    p_data.append(p_temp.tolist())\n",
    "            print('test--question done: ' + str(np.array(q_data).shape))\n",
    "            print('test--question_ans done: ' + str(np.array(qa_data).shape))\n",
    "            print('test--problem done: ' + str(np.array(p_data).shape))\n",
    "            return np.array(q_data).astype(float), np.array(qa_data).astype(float), np.array(p_data).astype(float)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/')\n",
    "from readdata import DataReader\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def getDataLoader(train_data_path, valid_data_path, test_data_path, max_step, n_knowledge_concept):\n",
    "    handle = DataReader(train_data_path, valid_data_path, test_data_path, max_step, n_knowledge_concept)\n",
    "\n",
    "    kc_data_train, respose_data_train, exercise_data_train = handle.getTrainData()\n",
    "    kc_data_valid, respose_data_valid, exercise_data_valid = handle.getValidData()\n",
    "    kc_data_test, respose_data_test, exercise_data_test = handle.getTestData()\n",
    "\n",
    "    return kc_data_train, respose_data_train, exercise_data_train,kc_data_valid, respose_data_valid, exercise_data_valid, kc_data_test, respose_data_test, exercise_data_test\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading train data...\n",
      "train--question done: (3293, 100)\n",
      "train--question_ans done: (3293, 100)\n",
      "train--problem done: (3293, 100)\n",
      "loading valid data...\n",
      "valid--question done: (1038, 100)\n",
      "valid--question_ans done: (1038, 100)\n",
      "valid--problem done: (1038, 100)\n",
      "loading test data...\n",
      "test--question done: (1032, 100)\n",
      "test--question_ans done: (1032, 100)\n",
      "test--problem done: (1032, 100)\n"
     ]
    }
   ],
   "source": [
    "train_kc_data, train_respond_data, train_exercise_data, \\\n",
    "        valid_kc_data, valid_respose_data, valid_exercise_data, \\\n",
    "        test_kc_data, test_respose_data, test_exercise_data \\\n",
    "        = getDataLoader(train_data_path, valid_data_path, test_data_path, max_step, n_knowledge_concept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_exercise_respond_data = train_respond_data * \\\n",
    "    n_exercise + train_exercise_data\n",
    "valid_exercise_respose_data = valid_respose_data * \\\n",
    "    n_exercise + valid_exercise_data\n",
    "test_exercise_respose_data = test_respose_data * \\\n",
    "    n_exercise + test_exercise_data\n",
    "adj_exercise_kc = np.loadtxt(data_dir + \"/exercise_kc_map.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3293"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.random.permutation(train_exercise_data.shape[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import utils as utils\n",
    "import embedd_loss as embedd_loss\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_exercise = n_exercise\n",
    "n_kc = n_knowledge_concept\n",
    "batch_size = batch_size\n",
    "exercise_embed_dim = exercise_embed_dim\n",
    "student_num = None\n",
    "nheads = num_heads\n",
    "alpha = alpha\n",
    "dropout = dropout\n",
    "# params = params\n",
    "mode = mode\n",
    "Lamda = Lamda\n",
    "hidden_dim = hidden_dim\n",
    "layer_num = layer_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Exercise_KC_GraphAttentionLayer(nn.Module):\n",
    "    def __init__(self, in_features, out_features, dropout, alpha, mode, concat=True):\n",
    "        super(Exercise_KC_GraphAttentionLayer, self).__init__()\n",
    "        self.dropout = dropout\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.alpha = alpha\n",
    "        self.concat = concat\n",
    "        self.mode =mode\n",
    "        self.W1 = nn.Parameter(torch.empty(size=(in_features, out_features)))\n",
    "        nn.init.kaiming_normal(self.W1)\n",
    "\n",
    "        if mode == 1 or mode == 3:\n",
    "            self.reduceDim = nn.Linear(in_features * 2, self.out_features, bias=True)\n",
    "            nn.init.kaiming_normal(self.reduceDim.weight)\n",
    "            nn.init.constant(self.reduceDim.bias, 0)\n",
    "        if mode != 1:\n",
    "            self.E = nn.Parameter(torch.empty(size=(in_features, out_features)))\n",
    "            nn.init.kaiming_normal(self.E)\n",
    "        if mode ==4:\n",
    "            self.U = nn.Parameter(torch.empty(size=(in_features, 1)))\n",
    "            nn.init.kaiming_normal(self.U)\n",
    "\n",
    "        self.a = nn.Parameter(torch.empty(size=(2*out_features, 1)))\n",
    "        nn.init.kaiming_normal(self.a)\n",
    "\n",
    "        self.leakyrelu = nn.LeakyReLU(self.alpha)\n",
    "\n",
    "    def forward(self, exercise_h, kc_h, adj_exercise_kc):\n",
    "        if self.concat:\n",
    "            kc_Wh = torch.mm(kc_h, self.W1)\n",
    "            exercise_Wh = torch.mm(exercise_h, self.W1)\n",
    "            a_input = self._prepare_attentional_mechanism_input(kc_Wh, exercise_Wh)\n",
    "            e = self.leakyrelu(torch.matmul(a_input, self.a).squeeze(2))\n",
    "            zero_vec = -9e15 * torch.ones_like(e)\n",
    "            attention = torch.where(adj_exercise_kc > 0, e, zero_vec)\n",
    "            attention = F.softmax(attention, dim=1)\n",
    "            new_kc_embed = torch.matmul(attention, kc_Wh)\n",
    "\n",
    "            if self.mode == 1:\n",
    "                exercises_embedd = torch.cat((new_kc_embed, exercise_h), dim=1)\n",
    "                exercises_embedd = self.reduceDim(exercises_embedd)\n",
    "            if self.mode == 2:\n",
    "                exercise_Eh = torch.mm(exercise_h, self.E)\n",
    "                exercises_embedd = new_kc_embed.mul(exercise_Eh)\n",
    "            if self.mode == 3:\n",
    "                exercise_Eh = torch.mm(exercise_h, self.E)\n",
    "                exercises_embedd = torch.cat((new_kc_embed, new_kc_embed.mul(exercise_Eh)), dim=1)\n",
    "                exercises_embedd = self.reduceDim(exercises_embedd)\n",
    "            if self.mode == 4:\n",
    "                u = torch.mm(exercise_h, self.U)\n",
    "                d_kt = torch.mm(new_kc_embed, self.E)\n",
    "                exercises_embedd = new_kc_embed + u * d_kt\n",
    "            return F.elu(exercises_embedd)\n",
    "\n",
    "    def _prepare_attentional_mechanism_input(self, kc_Wh, exercise_Wh):\n",
    "        N_kc = kc_Wh.size()[0]\n",
    "        N_exercise = exercise_Wh.size()[0]\n",
    "        Wh_repeated_in_chunks = exercise_Wh.repeat_interleave(N_kc, dim=0)\n",
    "        Wh_repeated_alternating = kc_Wh.repeat(N_exercise, 1)\n",
    "        all_combinations_matrix = torch.cat([Wh_repeated_in_chunks, Wh_repeated_alternating], dim=1)\n",
    "        return all_combinations_matrix.view(N_exercise, N_kc, 2 * self.out_features)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + ' (' + str(self.in_features) + ' -> ' + str(self.out_features) + ')'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm = nn.LSTM(exercise_embed_dim * 2, hidden_dim,\n",
    "               layer_num, batch_first=True, dropout=dropout)\n",
    "fc1 = nn.Linear(exercise_embed_dim + hidden_dim, hidden_dim, bias=True)\n",
    "fc2 = nn.Linear(hidden_dim, 1, bias=True)\n",
    "rel = nn.ReLU()\n",
    "\n",
    "exercise_embed = nn.Parameter(torch.randn(n_exercise, exercise_embed_dim))\n",
    "kc_embed = nn.Parameter(torch.randn(n_kc, exercise_embed_dim))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_650/995484167.py:8: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n",
      "  nn.init.kaiming_normal(W1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.1825, -0.0280,  0.1855,  ..., -0.3000,  0.2146, -0.0690],\n",
       "        [-0.0536, -0.2473, -0.2712,  ...,  0.0443,  0.2027, -0.0449],\n",
       "        [ 0.0055,  0.0771,  0.1112,  ...,  0.3770,  0.0359, -0.1277],\n",
       "        ...,\n",
       "        [-0.0626, -0.1749, -0.1026,  ..., -0.1415, -0.3213,  0.2746],\n",
       "        [ 0.1376,  0.0135, -0.3266,  ..., -0.0584,  0.2207,  0.0710],\n",
       "        [ 0.0377, -0.0575,  0.0066,  ..., -0.1305, -0.0184, -0.1846]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dropout = dropout\n",
    "in_features = exercise_embed_dim\n",
    "out_features = exercise_embed_dim\n",
    "alpha = alpha\n",
    "concat = True\n",
    "mode = mode\n",
    "W1 = nn.Parameter(torch.empty(size=(in_features, out_features)))\n",
    "nn.init.kaiming_normal(W1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_650/1761267380.py:2: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n",
      "  nn.init.kaiming_normal(reduceDim.weight)\n",
      "/tmp/ipykernel_650/1761267380.py:3: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.\n",
      "  nn.init.constant(reduceDim.bias, 0)\n",
      "/tmp/ipykernel_650/1761267380.py:6: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n",
      "  nn.init.kaiming_normal(E)\n",
      "/tmp/ipykernel_650/1761267380.py:9: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n",
      "  nn.init.kaiming_normal(U)\n",
      "/tmp/ipykernel_650/1761267380.py:12: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n",
      "  nn.init.kaiming_normal(a)\n"
     ]
    }
   ],
   "source": [
    "reduceDim = nn.Linear(in_features * 2, out_features, bias=True)\n",
    "nn.init.kaiming_normal(reduceDim.weight)\n",
    "nn.init.constant(reduceDim.bias, 0)\n",
    "\n",
    "E = nn.Parameter(torch.empty(size=(in_features, out_features)))\n",
    "nn.init.kaiming_normal(E)\n",
    "\n",
    "U = nn.Parameter(torch.empty(size=(in_features, 1)))\n",
    "nn.init.kaiming_normal(U)\n",
    "\n",
    "a = nn.Parameter(torch.empty(size=(2*out_features, 1)))\n",
    "nn.init.kaiming_normal(a)\n",
    "\n",
    "leakyrelu = nn.LeakyReLU(alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16891, 64])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exercise_embed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _prepare_attentional_mechanism_input(kc_Wh, exercise_Wh):\n",
    "    N_kc = kc_Wh.size()[0]\n",
    "    N_exercise = exercise_Wh.size()[0]\n",
    "    Wh_repeated_in_chunks = exercise_Wh.repeat_interleave(N_kc, dim=0)\n",
    "    Wh_repeated_alternating = kc_Wh.repeat(N_exercise, 1)\n",
    "    all_combinations_matrix = torch.cat(\n",
    "        [Wh_repeated_in_chunks, Wh_repeated_alternating], dim=1)\n",
    "    return all_combinations_matrix.view(N_exercise, N_kc, 2 * self.out_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 99])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kc_one_seq = train_respond_data[0:32, :]\n",
    "exercise_one_seq = train_exercise_data[0:32, :]\n",
    "exercise_respond_batch_seq = train_exercise_respond_data[0:32, :]\n",
    "target = train_exercise_respond_data[0:32, :]\n",
    "target = (target - 1) / n_exercise\n",
    "target = np.floor(target)\n",
    "input_kc = utils.varible(torch.LongTensor(kc_one_seq), gpu)\n",
    "input_exercise = utils.varible(torch.LongTensor(exercise_one_seq), gpu)\n",
    "input_exercise_respond = utils.varible(\n",
    "    torch.LongTensor(exercise_respond_batch_seq), gpu)\n",
    "target = utils.varible(torch.FloatTensor(target), gpu)\n",
    "target.shape\n",
    "target = target[:, 1:]\n",
    "target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3, 2, 1, 0],\n",
      "        [0, 4, 2, 0],\n",
      "        [2, 0, 4, 0]])\n",
      "tensor([[3, 2, 1, 0],\n",
      "        [3, 2, 1, 0],\n",
      "        [3, 2, 1, 0],\n",
      "        [0, 4, 2, 0],\n",
      "        [0, 4, 2, 0],\n",
      "        [0, 4, 2, 0],\n",
      "        [2, 0, 4, 0],\n",
      "        [2, 0, 4, 0],\n",
      "        [2, 0, 4, 0]])\n",
      "tensor([[3, 3, 3, 2, 2, 2, 1, 1, 1, 0, 0, 0],\n",
      "        [0, 0, 0, 4, 4, 4, 2, 2, 2, 0, 0, 0],\n",
      "        [2, 2, 2, 0, 0, 0, 4, 4, 4, 0, 0, 0]])\n",
      "tensor([[3, 2, 1, 0],\n",
      "        [0, 4, 2, 0],\n",
      "        [2, 0, 4, 0],\n",
      "        [3, 2, 1, 0],\n",
      "        [0, 4, 2, 0],\n",
      "        [2, 0, 4, 0],\n",
      "        [3, 2, 1, 0],\n",
      "        [0, 4, 2, 0],\n",
      "        [2, 0, 4, 0]])\n",
      "tensor([[3, 2, 1, 0],\n",
      "        [0, 4, 2, 0],\n",
      "        [2, 0, 4, 0],\n",
      "        [3, 2, 1, 0],\n",
      "        [3, 2, 1, 0],\n",
      "        [3, 2, 1, 0],\n",
      "        [0, 4, 2, 0],\n",
      "        [0, 4, 2, 0],\n",
      "        [0, 4, 2, 0],\n",
      "        [2, 0, 4, 0],\n",
      "        [2, 0, 4, 0],\n",
      "        [2, 0, 4, 0]])\n",
      "tensor([[3, 2, 1, 0, 3, 3, 3, 2, 2, 2, 1, 1, 1, 0, 0, 0],\n",
      "        [0, 4, 2, 0, 0, 0, 0, 4, 4, 4, 2, 2, 2, 0, 0, 0],\n",
      "        [2, 0, 4, 0, 2, 2, 2, 0, 0, 0, 4, 4, 4, 0, 0, 0]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor(np.random.randint(5, size = (3,4)))\n",
    "print(a)\n",
    "b = a.repeat_interleave(3, dim=0)\n",
    "print(b)\n",
    "c = a.repeat_interleave(3, dim=1)\n",
    "print(c)\n",
    "d = a.repeat(3,1)\n",
    "print(d)\n",
    "e = torch.cat([a, b], dim=0)\n",
    "print(e)\n",
    "f = torch.cat([a, c], dim=1)\n",
    "print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'self' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[101], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m exercise_embed \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mParameter(torch\u001b[39m.\u001b[39mrandn(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39mn_exercise, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexercise_embed_dim))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'self' is not defined"
     ]
    }
   ],
   "source": [
    "exercise_embed = nn.Parameter(torch.randn(self.n_exercise, self.exercise_embed_dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "kc_embed.shape\n",
    "exercise_embed.shape\n",
    "kc_Wh = torch.mm(kc_embed, W1)\n",
    "exercise_Wh = torch.mm(exercise_embed, W1)\n",
    "N_kc = kc_Wh.size()[0]\n",
    "N_exercise = exercise_Wh.size()[0]\n",
    "Wh_repeated_in_chunks = exercise_Wh.repeat_interleave(N_kc, dim=0)\n",
    "# 110개의 knowledge_concept에 대해 문항별 weight 생성\n",
    "Wh_repeated_alternating = kc_Wh.repeat(N_exercise, 1)\n",
    "# 16891개의 exercise에 대해 kc별 weight 생성\n",
    "all_combinations_matrix = torch.cat(\n",
    "    [Wh_repeated_in_chunks, Wh_repeated_alternating], dim=1)\n",
    "a_input = all_combinations_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1858010, 64])\n",
      "torch.Size([1858010, 64])\n"
     ]
    }
   ],
   "source": [
    "print(Wh_repeated_alternating.shape)\n",
    "print(Wh_repeated_in_chunks.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_650/2829987827.py:2: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n",
      "  nn.init.kaiming_normal(a)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 1])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = nn.Parameter(torch.empty(size=(2*64, 1)))\n",
    "nn.init.kaiming_normal(a)\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1858010"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "16891*110"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected condition, x and y to be on the same device, but condition is on cuda:0 and x and y are on cpu and cpu respectively",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[93], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m zero_vec \u001b[39m=\u001b[39m \u001b[39m-\u001b[39m\u001b[39m9e15\u001b[39m \u001b[39m*\u001b[39m torch\u001b[39m.\u001b[39mones_like(e)\n\u001b[1;32m      3\u001b[0m adj_exercise_kc \u001b[39m=\u001b[39m utils\u001b[39m.\u001b[39mvarible(torch\u001b[39m.\u001b[39mfrom_numpy(adj_exercise_kc), gpu)\n\u001b[0;32m----> 4\u001b[0m attention \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mwhere(adj_exercise_kc \u001b[39m>\u001b[39;49m \u001b[39m0\u001b[39;49m, e, zero_vec)\n\u001b[1;32m      5\u001b[0m attention \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39msoftmax(attention, dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m      6\u001b[0m new_kc_embed \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mmatmul(attention, kc_Wh)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected condition, x and y to be on the same device, but condition is on cuda:0 and x and y are on cpu and cpu respectively"
     ]
    }
   ],
   "source": [
    "e = leakyrelu(torch.matmul(a_input, a).squeeze(1))\n",
    "zero_vec = -9e15 * torch.ones_like(e)\n",
    "adj_exercise_kc = utils.varible(torch.from_numpy(adj_exercise_kc), gpu)\n",
    "attention = torch.where(adj_exercise_kc > 0, e, zero_vec)\n",
    "attention = F.softmax(attention, dim=1)\n",
    "new_kc_embed = torch.matmul(attention, kc_Wh)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'exercise_Wh' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m exercise_Wh\u001b[39m.\u001b[39mrepeat_interleave(\u001b[39m110\u001b[39m, dim\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\u001b[39m.\u001b[39mshape\n\u001b[1;32m      2\u001b[0m \u001b[39m# 110개의 knowledge_concept에 대해 문항별 weight 생성\u001b[39;00m\n\u001b[1;32m      3\u001b[0m kc_Wh\u001b[39m.\u001b[39mrepeat(\u001b[39m16891\u001b[39m, \u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mshape\n",
      "\u001b[0;31mNameError\u001b[0m: name 'exercise_Wh' is not defined"
     ]
    }
   ],
   "source": [
    "exercise_Wh.repeat_interleave(110, dim=0).shape\n",
    "# 110개의 knowledge_concept에 대해 문항별 weight 생성\n",
    "kc_Wh.repeat(16891, 1).shape\n",
    "# 16891개의 exercise에 대해 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise_KC_GraphAttentionLayer(self.exercise_embed_dim, self.exercise_embed_dim, dropout=self.dropout, alpha=self.alpha, mode=self.mode,\n",
    "# concat=True) for _ in range(self.nheads)]\n",
    "kc_h = kc_embed\n",
    "exercise_h = exercise_embed\n",
    "kc_Wh = torch.mm(kc_h, W1) #(110, 64)\n",
    "exercise_Wh = torch.mm(exercise_h, W1) #(16891, 64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "knowledge_tracing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
