{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import argparse\n",
    "from model import MODEL\n",
    "from run import train, test\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "from dataloader import getDataLoader\n",
    "from earlystop import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu = 0\n",
    "patience = 5\n",
    "max_iter = 100  # number of iterations\n",
    "init_lr = 0.005  # initial learning rate\n",
    "lr_decay = 0.75  # learning rate decay\n",
    "final_lr = 1E-5  # learning rate will not decrease after hitting this threshold\n",
    "dropout = 0.3\n",
    "exercise_embed_dim = 64  # hidden state dim for LSTM\n",
    "layer_num = 2  # layer number for LSTM\n",
    "max_step = 100  # the allowed maximum length of a sequence\n",
    "maxgradnorm = 50.0  # maximum gradient norm\n",
    "Lamda = 1  # hyper-parameter Lamda\n",
    "alpha = 0.2  # alpha\n",
    "num_heads = 4  # number of head attentions\n",
    "mode = 3  # mode of integration function\n",
    "# 1: ca / 2: mul / 3: ca mul / 4: rasch\n",
    "fold = '1'  # number of fold\n",
    "dataset = 'assist2009_B'\n",
    "\n",
    "#when dataset is assist2009_B\n",
    "batch_size = 32\n",
    "n_knowledge_concept = 110  # the kinds of unique questions in the dataset\n",
    "n_exercise = 16891  # the number of unique questions in the dataset\n",
    "data_dir = './data/assist2009_B'  # data directory\n",
    "data_name = 'assist2009_B'  # data set name\n",
    "\n",
    "memory_size = n_knowledge_concept\n",
    "lr = init_lr\n",
    "memory_key_state_dim = exercise_embed_dim\n",
    "memory_value_state_dim = exercise_embed_dim * 2\n",
    "\n",
    "train_data_path = data_dir + \"/\" + data_name + \"_train\" + fold + \".csv\"\n",
    "valid_data_path = data_dir + \"/\" + data_name + \"_valid\" + fold + \".csv\"\n",
    "test_data_path = data_dir + \"/\" + data_name + \"_test\" + fold + \".csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import itertools\n",
    "class DataReader():\n",
    "    def __init__(self, train_path, valid_path, test_path, maxstep, numofques):\n",
    "        self.train_path = train_path\n",
    "        self.valid_path = valid_path\n",
    "        self.test_path = test_path\n",
    "        self.maxstep = maxstep\n",
    "        self.numofques = numofques\n",
    "\n",
    "    def getTrainData(self):\n",
    "        print('loading train data...')\n",
    "        q_data= []\n",
    "        qa_data =[]\n",
    "        p_data= []\n",
    "        trainData = []\n",
    "        batch = 0\n",
    "        with open(self.train_path, 'r') as train:\n",
    "            for student, problem, ques, ans in itertools.zip_longest(*[train] * 4):\n",
    "                batch = batch +1\n",
    "                try:\n",
    "                    problem = [int(p) for p in problem.strip().strip(',').split(',')]\n",
    "                    ques = [int(q) for q in ques.strip().strip(',').split(',')]\n",
    "                    ans = [int(a) for a in ans.strip().strip(',').split(',')]\n",
    "                except:\n",
    "                    print(batch)\n",
    "                length = np.size(ques)\n",
    "                slices = length//self.maxstep + (1 if length%self.maxstep > 0 else 0)\n",
    "                for i in range(slices):\n",
    "                    q_temp = np.zeros(shape=[self.maxstep])\n",
    "                    qa_temp = np.zeros(shape=[self.maxstep])\n",
    "                    p_temp = np.zeros(shape=[self.maxstep])\n",
    "                    if length > 0:\n",
    "                        if length >= self.maxstep:\n",
    "                            l = self.maxstep\n",
    "                        else:\n",
    "                            l = length\n",
    "                        for j in range(l):\n",
    "                            q_temp[j] = ques[i*self.maxstep + j]\n",
    "                            qa_temp[j] = ans[i*self.maxstep + j]\n",
    "                            p_temp[j] = problem[i*self.maxstep + j]\n",
    "                        length = length - self.maxstep\n",
    "                    q_data.append(q_temp.tolist())\n",
    "                    qa_data.append(qa_temp.tolist())\n",
    "                    p_data.append(p_temp.tolist())\n",
    "            print('train--question done: ' + str(np.array(q_data).shape))\n",
    "            print('train--question_ans done: ' + str(np.array(qa_data).shape))\n",
    "            print('train--problem done: ' + str(np.array(p_data).shape))\n",
    "            return np.array(q_data).astype(float), np.array(qa_data).astype(float), np.array(p_data).astype(float)\n",
    "\n",
    "    def getValidData(self):\n",
    "        print('loading valid data...')\n",
    "        q_data= []\n",
    "        qa_data =[]\n",
    "        p_data= []\n",
    "        validData = []\n",
    "        batch = 0\n",
    "        with open(self.valid_path, 'r') as valid:\n",
    "            for student, problem, ques, ans in itertools.zip_longest(*[valid] * 4):\n",
    "                batch = batch +1\n",
    "                try:\n",
    "                    problem = [int(p) for p in problem.strip().strip(',').split(',')]\n",
    "                    ques = [int(q) for q in ques.strip().strip(',').split(',')]\n",
    "                    ans = [int(a) for a in ans.strip().strip(',').split(',')]\n",
    "                except:\n",
    "                    print(batch)\n",
    "                length = np.size(ques)\n",
    "                slices = length//self.maxstep + (1 if length%self.maxstep > 0 else 0)\n",
    "                for i in range(slices):\n",
    "                    q_temp = np.zeros(shape=[self.maxstep])\n",
    "                    qa_temp = np.zeros(shape=[self.maxstep])\n",
    "                    p_temp = np.zeros(shape=[self.maxstep])\n",
    "                    if length > 0:\n",
    "                        if length >= self.maxstep:\n",
    "                            l = self.maxstep\n",
    "                        else:\n",
    "                            l = length\n",
    "                        for j in range(l):\n",
    "                            q_temp[j] = ques[i*self.maxstep + j]\n",
    "                            qa_temp[j] = ans[i*self.maxstep + j]\n",
    "                            p_temp[j] = problem[i*self.maxstep + j]\n",
    "                        length = length - self.maxstep\n",
    "                    q_data.append(q_temp.tolist())\n",
    "                    qa_data.append(qa_temp.tolist())\n",
    "                    p_data.append(p_temp.tolist())\n",
    "            print('valid--question done: ' + str(np.array(q_data).shape))\n",
    "            print('valid--question_ans done: ' + str(np.array(qa_data).shape))\n",
    "            print('valid--problem done: ' + str(np.array(p_data).shape))\n",
    "            return np.array(q_data).astype(float), np.array(qa_data).astype(float), np.array(p_data).astype(float)\n",
    "\n",
    "\n",
    "    def getTestData(self):\n",
    "        print('loading test data...')\n",
    "        testData = []\n",
    "        q_data = []\n",
    "        qa_data = []\n",
    "        p_data = []\n",
    "        zero = [0 for i in range(self.numofques * 2)]\n",
    "        batch = 0\n",
    "        with open(self.test_path, 'r') as test:\n",
    "            for student, problem, ques, ans in itertools.zip_longest(*[test] * 4):\n",
    "                #length = int(length.strip().strip(','))\n",
    "                batch = batch + 1\n",
    "                try:\n",
    "                    problem = [int(p) for p in problem.strip().strip(',').split(',')]\n",
    "                    ques = [int(q) for q in ques.strip().strip(',').split(',')]\n",
    "                    ans = [int(a) for a in ans.strip().strip(',').split(',')]\n",
    "                except:\n",
    "                    print(batch)\n",
    "                length = np.size(ques)\n",
    "                slices = length // self.maxstep + (1 if length % self.maxstep > 0 else 0)\n",
    "                for i in range(slices):\n",
    "                    q_temp = np.zeros(shape=[self.maxstep])\n",
    "                    qa_temp = np.zeros(shape=[self.maxstep])\n",
    "                    p_temp = np.zeros(shape=[self.maxstep])\n",
    "                    if length > 0:\n",
    "                        if length >= self.maxstep:\n",
    "                            l = self.maxstep\n",
    "                        else:\n",
    "                            l = length\n",
    "                        for j in range(l):\n",
    "                            q_temp[j] = ques[i * self.maxstep + j]\n",
    "                            qa_temp[j] = ans[i * self.maxstep + j]\n",
    "                            p_temp[j] = problem[i * self.maxstep + j]\n",
    "                        length = length - self.maxstep\n",
    "                    q_data.append(q_temp.tolist())\n",
    "                    qa_data.append(qa_temp.tolist())\n",
    "                    p_data.append(p_temp.tolist())\n",
    "            print('test--question done: ' + str(np.array(q_data).shape))\n",
    "            print('test--question_ans done: ' + str(np.array(qa_data).shape))\n",
    "            print('test--problem done: ' + str(np.array(p_data).shape))\n",
    "            return np.array(q_data).astype(float), np.array(qa_data).astype(float), np.array(p_data).astype(float)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import itertools\n",
    "\n",
    "\n",
    "class DataReader():\n",
    "    def __init__(self, train_path, valid_path, test_path, maxstep, numofques):\n",
    "        self.train_path = train_path\n",
    "        self.valid_path = valid_path\n",
    "        self.test_path = test_path\n",
    "        self.maxstep = maxstep\n",
    "        self.numofques = numofques\n",
    "\n",
    "    def getTrainData(self):\n",
    "        print('loading train data...')\n",
    "        q_data = []\n",
    "        qa_data = []\n",
    "        p_data = []\n",
    "        trainData = []\n",
    "        batch = 0\n",
    "        with open(self.train_path, 'r') as train:\n",
    "            for student, problem, ques, ans in itertools.zip_longest(*[train] * 4):\n",
    "                batch = batch + 1\n",
    "                try:\n",
    "                    problem = [int(p)\n",
    "                               for p in problem.strip().strip(',').split(',')]\n",
    "                    ques = [int(q) for q in ques.strip().strip(',').split(',')]\n",
    "                    ans = [int(a) for a in ans.strip().strip(',').split(',')]\n",
    "                except:\n",
    "                    print(batch)\n",
    "                length = np.size(ques)\n",
    "                slices = length//self.maxstep + \\\n",
    "                    (1 if length % self.maxstep > 0 else 0)\n",
    "                for i in range(slices):\n",
    "                    q_temp = np.zeros(shape=[self.maxstep])\n",
    "                    qa_temp = np.zeros(shape=[self.maxstep])\n",
    "                    p_temp = np.zeros(shape=[self.maxstep])\n",
    "                    if length > 0:\n",
    "                        if length >= self.maxstep:\n",
    "                            l = self.maxstep\n",
    "                        else:\n",
    "                            l = length\n",
    "                        for j in range(l):\n",
    "                            q_temp[j] = ques[i*self.maxstep + j]\n",
    "                            qa_temp[j] = ans[i*self.maxstep + j]\n",
    "                            p_temp[j] = problem[i*self.maxstep + j]\n",
    "                        length = length - self.maxstep\n",
    "                    q_data.append(q_temp.tolist())\n",
    "                    qa_data.append(qa_temp.tolist())\n",
    "                    p_data.append(p_temp.tolist())\n",
    "            print('train--question done: ' + str(np.array(q_data).shape))\n",
    "            print('train--question_ans done: ' + str(np.array(qa_data).shape))\n",
    "            print('train--problem done: ' + str(np.array(p_data).shape))\n",
    "            return np.array(q_data).astype(float), np.array(qa_data).astype(float), np.array(p_data).astype(float)\n",
    "\n",
    "    def getValidData(self):\n",
    "        print('loading valid data...')\n",
    "        q_data = []\n",
    "        qa_data = []\n",
    "        p_data = []\n",
    "        validData = []\n",
    "        batch = 0\n",
    "        with open(self.valid_path, 'r') as valid:\n",
    "            for student, problem, ques, ans in itertools.zip_longest(*[valid] * 4):\n",
    "                batch = batch + 1\n",
    "                try:\n",
    "                    problem = [int(p)\n",
    "                               for p in problem.strip().strip(',').split(',')]\n",
    "                    ques = [int(q) for q in ques.strip().strip(',').split(',')]\n",
    "                    ans = [int(a) for a in ans.strip().strip(',').split(',')]\n",
    "                except:\n",
    "                    print(batch)\n",
    "                length = np.size(ques)\n",
    "                slices = length//self.maxstep + \\\n",
    "                    (1 if length % self.maxstep > 0 else 0)\n",
    "                for i in range(slices):\n",
    "                    q_temp = np.zeros(shape=[self.maxstep])\n",
    "                    qa_temp = np.zeros(shape=[self.maxstep])\n",
    "                    p_temp = np.zeros(shape=[self.maxstep])\n",
    "                    if length > 0:\n",
    "                        if length >= self.maxstep:\n",
    "                            l = self.maxstep\n",
    "                        else:\n",
    "                            l = length\n",
    "                        for j in range(l):\n",
    "                            q_temp[j] = ques[i*self.maxstep + j]\n",
    "                            qa_temp[j] = ans[i*self.maxstep + j]\n",
    "                            p_temp[j] = problem[i*self.maxstep + j]\n",
    "                        length = length - self.maxstep\n",
    "                    q_data.append(q_temp.tolist())\n",
    "                    qa_data.append(qa_temp.tolist())\n",
    "                    p_data.append(p_temp.tolist())\n",
    "            print('valid--question done: ' + str(np.array(q_data).shape))\n",
    "            print('valid--question_ans done: ' + str(np.array(qa_data).shape))\n",
    "            print('valid--problem done: ' + str(np.array(p_data).shape))\n",
    "            return np.array(q_data).astype(float), np.array(qa_data).astype(float), np.array(p_data).astype(float)\n",
    "\n",
    "    def getTestData(self):\n",
    "        print('loading test data...')\n",
    "        testData = []\n",
    "        q_data = []\n",
    "        qa_data = []\n",
    "        p_data = []\n",
    "        zero = [0 for i in range(self.numofques * 2)]\n",
    "        batch = 0\n",
    "        with open(self.test_path, 'r') as test:\n",
    "            for student, problem, ques, ans in itertools.zip_longest(*[test] * 4):\n",
    "                #length = int(length.strip().strip(','))\n",
    "                batch = batch + 1\n",
    "                try:\n",
    "                    problem = [int(p)\n",
    "                               for p in problem.strip().strip(',').split(',')]\n",
    "                    ques = [int(q) for q in ques.strip().strip(',').split(',')]\n",
    "                    ans = [int(a) for a in ans.strip().strip(',').split(',')]\n",
    "                except:\n",
    "                    print(batch)\n",
    "                length = np.size(ques)\n",
    "                slices = length // self.maxstep + \\\n",
    "                    (1 if length % self.maxstep > 0 else 0)\n",
    "                for i in range(slices):\n",
    "                    q_temp = np.zeros(shape=[self.maxstep])\n",
    "                    qa_temp = np.zeros(shape=[self.maxstep])\n",
    "                    p_temp = np.zeros(shape=[self.maxstep])\n",
    "                    if length > 0:\n",
    "                        if length >= self.maxstep:\n",
    "                            l = self.maxstep\n",
    "                        else:\n",
    "                            l = length\n",
    "                        for j in range(l):\n",
    "                            q_temp[j] = ques[i * self.maxstep + j]\n",
    "                            qa_temp[j] = ans[i * self.maxstep + j]\n",
    "                            p_temp[j] = problem[i * self.maxstep + j]\n",
    "                        length = length - self.maxstep\n",
    "                    q_data.append(q_temp.tolist())\n",
    "                    qa_data.append(qa_temp.tolist())\n",
    "                    p_data.append(p_temp.tolist())\n",
    "            print('test--question done: ' + str(np.array(q_data).shape))\n",
    "            print('test--question_ans done: ' + str(np.array(qa_data).shape))\n",
    "            print('test--problem done: ' + str(np.array(p_data).shape))\n",
    "            return np.array(q_data).astype(float), np.array(qa_data).astype(float), np.array(p_data).astype(float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/')\n",
    "from readdata import DataReader\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def getDataLoader(train_data_path, valid_data_path, test_data_path, max_step, n_knowledge_concept):\n",
    "    handle = DataReader(train_data_path, valid_data_path, test_data_path, max_step, n_knowledge_concept)\n",
    "\n",
    "    kc_data_train, respose_data_train, exercise_data_train = handle.getTrainData()\n",
    "    kc_data_valid, respose_data_valid, exercise_data_valid = handle.getValidData()\n",
    "    kc_data_test, respose_data_test, exercise_data_test = handle.getTestData()\n",
    "\n",
    "    return kc_data_train, respose_data_train, exercise_data_train,kc_data_valid, respose_data_valid, exercise_data_valid, kc_data_test, respose_data_test, exercise_data_test\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading train data...\n",
      "train--question done: (3293, 100)\n",
      "train--question_ans done: (3293, 100)\n",
      "train--problem done: (3293, 100)\n",
      "loading valid data...\n",
      "valid--question done: (1038, 100)\n",
      "valid--question_ans done: (1038, 100)\n",
      "valid--problem done: (1038, 100)\n",
      "loading test data...\n",
      "test--question done: (1032, 100)\n",
      "test--question_ans done: (1032, 100)\n",
      "test--problem done: (1032, 100)\n"
     ]
    }
   ],
   "source": [
    "train_kc_data, train_respond_data, train_exercise_data, \\\n",
    "        valid_kc_data, valid_respose_data, valid_exercise_data, \\\n",
    "        test_kc_data, test_respose_data, test_exercise_data \\\n",
    "        = getDataLoader(train_data_path, valid_data_path, test_data_path, max_step, n_knowledge_concept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_exercise_respond_data = train_respond_data * \\\n",
    "    n_exercise + train_exercise_data\n",
    "valid_exercise_respose_data = valid_respose_data * \\\n",
    "    n_exercise + valid_exercise_data\n",
    "test_exercise_respose_data = test_respose_data * \\\n",
    "    n_exercise + test_exercise_data\n",
    "adj_exercise_kc = np.loadtxt(data_dir + \"/exercise_kc_map.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16891"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(adj_exercise_kc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16891"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can only concatenate str (not \"int\") to str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m memory_key_state_dim \u001b[39m=\u001b[39m exercise_embed_dim\n\u001b[1;32m      4\u001b[0m memory_value_state_dim \u001b[39m=\u001b[39m exercise_embed_dim \u001b[39m*\u001b[39m \u001b[39m2\u001b[39m\n\u001b[0;32m----> 6\u001b[0m train_data_path \u001b[39m=\u001b[39m data_dir \u001b[39m+\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39m/\u001b[39;49m\u001b[39m\"\u001b[39;49m \u001b[39m+\u001b[39;49m data_name \u001b[39m+\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39m_train\u001b[39;49m\u001b[39m\"\u001b[39;49m \u001b[39m+\u001b[39;49m fold \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m.csv\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m      7\u001b[0m valid_data_path \u001b[39m=\u001b[39m data_dir \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m/\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m data_name \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m_valid\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m fold \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m.csv\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m      8\u001b[0m test_data_path \u001b[39m=\u001b[39m data_dir \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m/\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m data_name \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m_test\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m fold \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m.csv\u001b[39m\u001b[39m\"\u001b[39m\n",
      "\u001b[0;31mTypeError\u001b[0m: can only concatenate str (not \"int\") to str"
     ]
    }
   ],
   "source": [
    "memory_size = n_knowledge_concept\n",
    "lr = init_lr\n",
    "memory_key_state_dim = exercise_embed_dim\n",
    "memory_value_state_dim = exercise_embed_dim * 2\n",
    "\n",
    "train_data_path = data_dir + \"/\" + data_name + \"_train\" + fold + \".csv\"\n",
    "valid_data_path = data_dir + \"/\" + data_name + \"_valid\" + fold + \".csv\"\n",
    "test_data_path = data_dir + \"/\" + data_name + \"_test\" + fold + \".csv\"\n",
    "\n",
    "train_kc_data, train_respond_data, train_exercise_data, \\\n",
    "    valid_kc_data, valid_respose_data, valid_exercise_data, \\\n",
    "    test_kc_data, test_respose_data, test_exercise_data \\\n",
    "    = getDataLoader(train_data_path, valid_data_path, test_data_path, max_step, n_knowledge_concept)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "knowledge_tracing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
